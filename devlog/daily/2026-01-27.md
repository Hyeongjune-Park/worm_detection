# 2026-01-27 — 코드 구조 전면 변경 기록

## 변경 개요

`design_spec.md` 기반으로 **자동 탐지(auto-detection) 파이프라인**을 **Human-in-the-Loop 다중 센서 교차검증 파이프라인**으로 전면 재구축.

### 이전 구조 (Before)
```
VideoReader → Preprocessor → MotionDetector(배경차분+blob) → MultiObjectTracker(Hungarian assignment, 자동 트랙 생성) → optional SAM2 Segmenter → ArtifactWriter
```
- 자동으로 blob 탐지 → 트랙 생성/연관
- 단일 센서(모션 기반)
- 4-state: ACTIVE, OCCLUDED, EXITED, DEAD

### 현재 구조 (After)
```
사용자 seed(select_seeds.py) → 트랙 초기화 →
매 프레임, 트랙별:
  Kalman predict → ROI crop → 3 센서(SAM2, Template, KLT) → QA Fusion → KF update → State machine → Head estimation → Output
```
- 사용자가 초기 bbox 지정 (human seed)
- 3개 센서 교차검증 (SAM2 + Template NCC + KLT optical flow)
- 7-state: ACTIVE, UNCERTAIN, OCCLUDED, MERGED, EXITED, DEAD_CANDIDATE, NEEDS_RESEED
- 좌표 일관성 기반 QA (bbox/area 기반 rollback 금지)

---

## 작동 흐름 상세

### 1. 사전 준비
1. `select_arena.py` — 영상에서 실험 영역(arena) 사각형 지정 → `arena.yaml`
2. `select_seeds.py` — 첫 프레임에서 각 애벌레에 bbox 지정 (최대 10개) → `seeds.yaml`

### 2. 파이프라인 실행 (`run.py` → `pipeline/runner.py`)
1. `seeds.yaml`에서 트랙 생성: 각 seed bbox 중심으로 `KalmanFilter2D` 초기화
2. 첫 프레임에서 3개 센서 초기화:
   - **Template**: bbox 영역에서 gray + Sobel edge patch 추출
   - **KLT**: bbox 영역에서 `goodFeaturesToTrack` 초기화
   - **SAM2**: (프레임별 independent, 초기화 불필요)

### 3. 매 프레임 Per-Track 루프
```
a) Kalman predict → pred_center
b) ROI = pred_center 중심 384x384 (arena clamp)
c) 센서 측정:
   - SAM2: ROI crop에서 box prompt → mask → centroid, PCA endpoints, border_touch
   - Template: ROI 내 NCC 매칭 → center_tpl
   - KLT: optical flow (forward-backward check) → center_klt (median)
d) QA Fusion:
   - d_pred = ||center_sam2 - pred_center||
   - d_tpl  = ||center_sam2 - center_tpl||
   - Case A: 모두 일치 + border_touch 낮음 → SAM2 채택
   - Case B: 불일치 → Template 또는 KLT 사용, UNCERTAIN
   - Case C: 모두 불신 → predict only, OCCLUDED
e) Kalman update (fusion이 승인한 경우만)
f) Track 필드 갱신 (last_center, sensor_used, quality_score)
g) Head 추정: SAM2 mask PCA → major axis endpoints → 이동방향 정렬
h) State machine: 상태 전이 결정
i) Template 업데이트 (품질 높을 때만 slow blend)
j) Immobility check → DEAD_CANDIDATE
k) Event logging (상태 변경 시)
```

### 4. 프레임 간 처리
- **Merge detection**: 트랙 간 거리 < threshold → 양쪽 MERGED (통합 금지)
- 분리되면 ACTIVE 복귀

### 5. 출력
- `tracks.csv`: frame_idx, time_sec, track_id, center_x/y, head_x/y, state, quality_score, sensor_used, bbox, area
- `events.jsonl`: 상태 전이 이벤트
- `overlay.mp4`: arena, bbox, center(원), head(화살표), track_id+state 텍스트 (상태별 색상)

---

## 파일 변경 목록

### 신규 파일
| 파일 | 설명 |
|------|------|
| `select_seeds.py` | 초기 seed bbox 지정 GUI 도구 |
| `sensors/__init__.py` | 센서 패키지 |
| `sensors/base.py` | `Sensor` ABC + `SensorResult` dataclass |
| `sensors/template_sensor.py` | Gray+Edge NCC 템플릿 매칭 센서 |
| `sensors/klt_sensor.py` | KLT optical flow 센서 |
| `sensors/sam2_sensor.py` | SAM2 센서 (prev_mask 힌트 캐싱, fallback 제거) |
| `sensors/head_estimator.py` | PCA + 이동방향 기반 head 추정 |
| `qa/__init__.py` | QA 패키지 |
| `qa/fusion.py` | 다중 센서 교차검증 + 융합 로직 |
| `tracking/state_machine.py` | 7-state 상태 머신 |
| `io_utils/overlay.py` | 오버레이 그리기 (상태별 색상) |
| `tracking/state_io.py` | 청크 간 Track 상태 직렬화/역직렬화 |

### 수정 파일
| 파일 | 변경 내용 |
|------|----------|
| `tracking/track.py` | TrackState 4→7개, Track에 센서 메모리/품질/head 필드 추가 |
| `tracking/kalman.py` | q/r 생성자 파라미터, `set_measurement_noise()` 추가 |
| `roi/roi_manager.py` | 고정 크기 ROI(384), Kalman center 직접 입력, arena clamp |
| `pipeline/runner.py` | 전면 재작성: per-track 센서 루프 |
| `run.py` | `--seeds` 인자 추가, arena injection 경로 변경 |
| `config.yaml` | sensors/qa/head/arena 섹션 추가, detection.blob/segmentation 제거 |
| `io_utils/artifacts.py` | CSV 컬럼 확장 (head, sensor_used, quality), EventWriter 추가 |
| `CLAUDE.md` | 새 아키텍처 반영 |

### 미사용 파일 (레거시, 참조용 보존)
| 파일 | 이유 |
|------|------|
| `detection/motion_detector.py` | 자동 탐지 제거 (보조 힌트로만 가능) |
| `detection/background_model.py` | 위와 동일 |
| `tracking/multi_tracker.py` | Hungarian assignment 기반 MOT 제거 |
| `tracking/association.py` | 위와 동일 |
| `segmentation/base.py`, `sam2_adapter.py` | sensors/로 대체 |

---

## 핵심 설계 원칙 (design_spec.md 준수)

1. **SAM2 출력 ≠ 정답** → QA 교차검증 통과 시에만 채택
2. **bbox/area 변화만으로 rollback 금지** → 좌표 일관성 기반 판단
3. **ROI 무한 확장 금지** → 실패 누적 시 NEEDS_RESEED
4. **트랙 통합 금지** → MERGED 상태로 개별 유지
5. **목표는 center/head 좌표 정확도** (mask 품질 자체가 아님)
6. **사용자 seed 필수** → 자동 새 트랙 생성 없음

---

---

## ChatGPT 피드백 반영 (Fix 1~7)

### Fix 1: MotionMaskSensor fallback 제거
- `sam2_sensor.py`: `MotionMaskSensor` 클래스 및 fallback 완전 제거
- SAM2 사용 불가 시 → `None` 반환 → TPL+KLT+Kalman만으로 운용
- 이유: 전역 모션 기반 fallback은 per-track ROI 설계 철학과 충돌

### Fix 2: QA 거리 임계값 ROI 정규화
- `qa/fusion.py`: 고정 px 임계값 → ROI diagonal 대비 비율 (`dist_pred_ratio` 등)
- `config.yaml`: `dist_pred_thresh: 50.0` → `dist_pred_ratio: 0.12`
- `fuse()` 함수에 `roi_size` 파라미터 추가
- 이유: 해상도/ROI 크기 변화에도 일관된 QA 기준 유지

### Fix 3: MERGED 상태 시 SAM2 불신 + 이벤트 로깅
- `qa/fusion.py`: `is_merged` 파라미터 추가. True이면 SAM2 결과 무시 (겹친 트랙 하나로 인식 방지)
- `pipeline/runner.py`: `roi_size`, `is_merged` 전달, `cache_good_result()` 호출
- `tracking/state_machine.py`: `check_merges()` → MERGE_ENTER/MERGE_EXIT 이벤트 반환
- `pipeline/runner.py`: merge 이벤트를 `events.jsonl`에 기록

### Fix 4: Head estimator edge-based PCA fallback
- `sensors/head_estimator.py`: SAM2 mask 없을 때 Canny edge PCA로 장축 endpoints 추출
- `estimate()` 시그니처 확장: `crop_gray`, `roi_origin`, `fused_center` 추가
- `pipeline/runner.py`: head_est.estimate()에 새 파라미터 전달

### Fix 5: select_seeds.py 프레임 탐색
- `FrameLoader` 클래스: 비디오/이미지 폴더에서 임의 프레임 접근
- `--frame` CLI 옵션: 시작 프레임 인덱스 지정
- 좌/우 화살표 또는 `,`/`.` 키로 프레임 이동
- `seeds.yaml`에 `frame_idx` 필드 추가

### Fix 6: 청크 간 상태 직렬화
- `tracking/state_io.py` 신규: `save_state()` / `load_state()` 함수
- `Track.serialize_state()` → JSON → 파일 저장/복원
- Kalman 상태(x, P), 트랙 상태, 품질 점수 등 완전 복원

### Fix 7: SAM2 prev_mask/center 힌트 캐싱
- `sam2_sensor.py`: `_prev_masks`, `_prev_centers`, `_pending` 딕셔너리 추가
- QA 통과 프레임의 mask center → 다음 프레임 point prompt 힌트로 사용
- `cache_good_result(track_id)`: QA 확정 후 호출하여 캐시 확정
- 이유: 매 프레임 box-only prompt는 불안정, 이전 좋은 결과를 힌트로 활용

---

## 미구현 사항 (추후)

- `reseed_tool.py`: 특정 트랙/프레임에서 사용자 재지정
- ROI 좌표를 CSV에 기록 (현재 빈값)
